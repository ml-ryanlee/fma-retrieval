{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qmJZ0u0X5zc",
        "outputId": "857fe0b7-3909-4731-84b7-160b2bd47dd2"
      },
      "outputs": [],
      "source": [
        "!pip install datasets faiss-cpu beir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2uCPEBpYe8x"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertConfig\n",
        "from collections import defaultdict\n",
        "import faiss\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Xyyd7caC-V",
        "outputId": "bd2a1d07-fa55-4be0-d6c5-06266f2383ee"
      },
      "outputs": [],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/cs566"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfY7uZXk2P3M"
      },
      "outputs": [],
      "source": [
        "# Load the embeddings from the JSONL file\n",
        "embeddings_df = pd.read_json('../data/embeddings.jsonl', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwHD6xsW4jmW"
      },
      "outputs": [],
      "source": [
        "def normalize_embedding(x):\n",
        "    # Convert to numpy array if it's not already\n",
        "    arr = np.array(x)\n",
        "\n",
        "    # If it's 3D with shape (1, 64, 322), take mean across last dimension\n",
        "    if len(arr.shape) == 3:\n",
        "        arr = np.mean(arr, axis=2).squeeze()\n",
        "\n",
        "    # Normalize the vector\n",
        "    norm = np.linalg.norm(arr)\n",
        "    if norm > 0:  # Avoid division by zero\n",
        "        return arr / norm\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw3dnvbJaBsX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert embedding columns from lists to numpy arrays\n",
        "embedding_columns = [\"audio\", \"q_audio\", \"q_audio_eq\", \"q_audio_pitch\", \"q_audio_back\"]\n",
        "\n",
        "for col in embedding_columns:\n",
        "    # Check if the column exists in the DataFrame\n",
        "    if col in embeddings_df.columns:\n",
        "        # Convert to numpy array, take mean across last dimension if needed, and normalize\n",
        "        embeddings_df[col] = embeddings_df[col].apply(\n",
        "            lambda x: normalize_embedding(x) if x is not None else None\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaljjALZ0jtR",
        "outputId": "497923f7-5198-4c1c-9cab-04e922b4b1d4"
      },
      "outputs": [],
      "source": [
        "for col in embedding_columns:\n",
        "    shape = embeddings_df.iloc[0][col].shape\n",
        "    print(col, shape)\n",
        "\n",
        "embeddings_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqDfcg37rJ7-"
      },
      "source": [
        "## Set Dataset Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrM2SBgPrL1d"
      },
      "outputs": [],
      "source": [
        "# Determine train/test split indices\n",
        "train_test_split=0.7\n",
        "random.seed(42)\n",
        "dataset_size = len(embeddings_df)\n",
        "train_size = int(dataset_size * train_test_split)\n",
        "indices = list(range(dataset_size))\n",
        "random.shuffle(indices)\n",
        "train_indices = set(indices[:train_size])\n",
        "test_indices = set(indices[train_size:])\n",
        "\n",
        "# extract rows for test_indices from dataframe\n",
        "test_df = embeddings_df[embeddings_df.index.isin(test_indices)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LcMqw9DsLB8"
      },
      "source": [
        "## Perform Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH5xL5WfusEy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the TSV file with the qrels data\n",
        "def load_qrels_from_tsv(file_path):\n",
        "    \"\"\"\n",
        "    Load qrels from a TSV file into a dictionary format required by EvaluateRetrieval.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the TSV file containing qrels data\n",
        "\n",
        "    Returns:\n",
        "        dict: A nested dictionary of {query_id: {doc_id: relevance_score}}\n",
        "    \"\"\"\n",
        "    # Read the TSV file\n",
        "    # Assuming format: query_id, 0, doc_id, relevance_score\n",
        "    # The second column (0) is typically an iteration which we can ignore\n",
        "    df = pd.read_csv(file_path, sep='\\t', header=None,\n",
        "                     names=['query_id', 'iteration', 'doc_id', 'relevance'])\n",
        "\n",
        "    # Convert to the required dictionary format\n",
        "    qrels_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        query_id = str(row['query_id'])\n",
        "        doc_id = str(row['doc_id'])\n",
        "        relevance = int(row['relevance'])\n",
        "\n",
        "        # Initialize the inner dictionary if needed\n",
        "        if query_id not in qrels_dict:\n",
        "            qrels_dict[query_id] = {}\n",
        "\n",
        "        # Add the document relevance\n",
        "        qrels_dict[query_id][doc_id] = relevance\n",
        "\n",
        "    return qrels_dict\n",
        "\n",
        "def format_retrievals_faiss(qids, retrieved_pids, scores):\n",
        "    \"\"\"\n",
        "    Format FAISS search results for BEIR evaluation\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    qids : list or Series\n",
        "        List of query IDs\n",
        "    retrieved_pids : list of lists\n",
        "        List of lists containing retrieved document IDs for each query\n",
        "    scores : numpy.ndarray\n",
        "        Matrix of similarity scores from FAISS search\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary mapping query IDs to {doc_id: score} dictionaries\n",
        "    \"\"\"\n",
        "    retrievals = {}\n",
        "\n",
        "    # Convert qids to list if it's a pandas Series\n",
        "    if hasattr(qids, 'tolist'):\n",
        "        qids = qids.tolist()\n",
        "\n",
        "    for i, qid in enumerate(qids):\n",
        "        # Make sure qid is a string\n",
        "        qid_str = str(qid)\n",
        "        retrievals[qid_str] = {}\n",
        "\n",
        "        for j, pid in enumerate(retrieved_pids[i]):\n",
        "            # Make sure pid is a string\n",
        "            pid_str = str(pid)\n",
        "            # Convert numpy float to Python float\n",
        "            score = float(scores[i][j])\n",
        "            retrievals[qid_str][pid_str] = score\n",
        "\n",
        "    # Validate structure\n",
        "    if len(retrievals) == 0:\n",
        "        print(\"Warning: Empty retrievals dictionary\")\n",
        "    else:\n",
        "        sample_qid = next(iter(retrievals))\n",
        "        if len(retrievals[sample_qid]) == 0:\n",
        "            print(f\"Warning: No documents for query {sample_qid}\")\n",
        "\n",
        "    return retrievals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQaI5fBx7anZ",
        "outputId": "9a534d65-3921-4197-a3d4-f360980d891d"
      },
      "outputs": [],
      "source": [
        "# download qrels\n",
        "qrels_file_path = \"data/qrels.tsv\"\n",
        "qrels = load_qrels_from_tsv(qrels_file_path)\n",
        "\n",
        "# extract query embeddings\n",
        "doc_embeddings = np.vstack(embeddings_df[\"audio\"])\n",
        "\n",
        "# get unique result for each query\n",
        "query_columns = [\"q_audio\", \"q_audio_eq\", \"q_audio_pitch\", \"q_audio_back\"]\n",
        "for query in query_columns:\n",
        "    query_embeddings = np.vstack(test_df[query])\n",
        "\n",
        "    # stack embeddings\n",
        "    k = 10\n",
        "    d = embeddings_df.iloc[0]['audio'].shape[0]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(doc_embeddings)\n",
        "    D, I = index.search(query_embeddings, k)\n",
        "\n",
        "    # extract qids and pids\n",
        "    qids = test_df[\"qid\"]\n",
        "    pids = embeddings_df[\"pid\"]\n",
        "    retrieved_pids = [[pids[idx] for idx in row] for row in I]\n",
        "    retrievals = format_retrievals_faiss(qids, retrieved_pids, D)\n",
        "\n",
        "    # obtain retrievals\n",
        "    k_values = [1, 3, 5, 10]\n",
        "    ndcg, map, recall, precision = EvaluateRetrieval.evaluate(qrels, retrievals, k_values)\n",
        "    print(f\"\\nResults for {query}:\")\n",
        "    print(f\"NDCG: {ndcg}\")\n",
        "    print(f\"MAP: {map}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"Precision: {precision}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
